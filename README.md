# ğŸ›¡ï¸ AI Sentinel â€“ Intelligent Log Anomaly Detector

AI Sentinel is an intelligent **cybersecurity monitoring system** that detects anomalies in system log data using **Deep Learning (Autoencoder)** and explains the root cause with **AI Agents (CrewAI + GPT)**.

---

## ğŸš€ Overview

Most large-scale systems (like data servers or distributed file systems) generate millions of log entries daily.  
Identifying abnormal patterns manually is nearly impossible â€” thatâ€™s where **AI Sentinel** comes in.

1. It learns normal log patterns using a **Deep Learning Autoencoder model**.
2. Detects unusual behavior (anomalies) in new logs.
3. Uses **AI agents** to explain *why* it happened and *what action* to take.
4. Ensures safe AI responses using a **lightweight Guardrail** filter.

---

## ğŸ§  Tech Stack

- **Python 3.10 / 3.13**
- **TensorFlow (Autoencoder model)**
- **CrewAI (Multi-Agent Framework)**
- **Streamlit (Frontend + Deployment)**
- **OpenAI GPT Integration**
- **CI/CD:** Automated deployment via **GitHub â†’ Render/Streamlit Cloud**

---

## ğŸ—ï¸ Architecture

1. **Autoencoder Model (`ai_sentinel_autoencoder.h5`)**
   - Learns normal system log patterns.
   - High reconstruction error = anomaly detected.

2. **Streamlit App**
   - Upload `.csv` log files.
   - Visualizes normal vs anomalous logs.
   - Calls CrewAI pipeline for explanation and actions.

3. **CrewAI Agents**
   - `Detection Agent` â†’ Explains anomaly cause.
   - `Severity Agent` â†’ Classifies as *Critical, Major, Minor*.
   - `Action Agent` â†’ Suggests operations fix.

4. **Guardrail**
   - Filters GPT outputs for irrelevant or technical junk (tracebacks, code, etc.).
   - Keeps responses short, relevant, and clean.

---

## ğŸ§© Dataset Used

The project uses **HDFS (Hadoop Distributed File System) Logs** â€”  
a real dataset of server log sequences from large distributed systems.  

It represents how files are read/written/replicated across clusters.  
Each â€œBlockIdâ€ represents a file block operation â€” like:
Block 14205 starts replication
Block 14205 completed successfully
Block 14205 corrupted

When any unusual pattern occurs, the autoencoder flags it as **Anomaly**.

---

## ğŸ“¦ Example Workflow

1. Upload a preprocessed HDFS `.csv` file.
2. Model reconstructs the sequence â†’ finds anomaly (based on error).
3. CrewAI agents analyze and generate:
   - **Reason:** Why it happened.
   - **Severity:** Critical/Major/Minor.
   - **Suggested Action:** What to do next.

---

## ğŸ§© Lightweight Guardrail Explanation

- Guardrail runs after GPT gives a response.
- It removes unwanted text like:
  - â€œTracebackâ€, â€œErrorâ€, â€œExceptionâ€, or â€œline â€¦â€
- If a non-log file (wrong CSV) is uploaded:
  - The model tries to read it.
  - Since data pattern doesnâ€™t match trained format, reconstruction error spikes.
  - The system automatically classifies all rows as **Anomaly**.
  - CrewAI still runs but responses will be *cleanly filtered* via Guardrail.

This shows robustness and safe output handling.

---

## ğŸ” CI/CD Implementation

- The project is **auto-deployed** through GitHub â†’ Render.
- Every code commit triggers a build pipeline.
- If the build succeeds, the app updates automatically.
- You can verify builds under the **Render dashboard (Logs tab)**.

---

## ğŸ’¡ Future Improvements

- Add live log streaming.
- Connect to real server monitoring dashboards.
- Include GPT response validation using advanced Guardrails or LlamaGuard.

---

## ğŸ™Œ Achievements

âœ… Deep Learning-based anomaly detection  
âœ… Multi-agent reasoning pipeline  
âœ… Lightweight guardrail for safe AI responses  
âœ… First-ever CI/CD deployment via GitHub  
âœ… Successful live demo using Streamlit Cloud

---

## ğŸ§‘â€ğŸ’» Author

**Kiruthika Ramalingam**  
AI & Automation Enthusiast | DDS Challenge 2025 Participant  
ğŸ“ UAE | ğŸ”— [LinkedIn](https://linkedin.com/in/kiruthikaramalingam)